{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import tqdm\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAuthConnection():\n",
    "    consumerApiKey = 'Tx4p4obJsXFwO5eHKEbsfidJq'\n",
    "    consumerApiSecret = 'uoxlO5zt48FYPjEJjWEa49ukHe1oWsWahvPCwbf6ncudRi713j'\n",
    "    acessToken = '294569456-ZwBlFWdoYP9OazssEsxnoargsaAPrWHWfjUj6cH3'\n",
    "    acessTokenSecret  = 'J6fCig6s1tsnDtn26ISbZRPVQryRWtfHftb76MNnQLj9u'\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(consumerApiKey, consumerApiSecret)\n",
    "    #auth = tweepy.AppAuthHandler(consumerApiKey, consumerApiSecret)\n",
    "    auth.set_access_token(acessToken, acessTokenSecret)\n",
    "    \n",
    "    return tweepy.API(auth , wait_on_rate_limit = True,wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = makeAuthConnection()\n",
    "# for status in tweepy.Cursor(api.search, q='tweepy').items(10):\n",
    "#     print(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRemainingSearchCount():\n",
    "    jsonString = api.rate_limit_status()['resources']['search']['/search/tweets']\n",
    "    upperLimit = jsonString['limit']\n",
    "    remiaingFetch = jsonString['remaining']\n",
    "    #resetTime = jsonString['reset']/60000 \n",
    "    print (jsonString)\n",
    "    return upperLimit,remiaingFetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'limit': 180, 'remaining': 180, 'reset': 1573904010}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 180)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkRemainingSearchCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchString = '##housefull4review'\n",
    "# searchFilter = ' AND -filter:retweets AND -filter:replies AND -filter:links and -filter:videos'\n",
    "# tweetList = tweepy.Cursor(api.search,q = searchString + searchFilter ,\n",
    "#                             lang  = 'en',include_entities=False,tweet_mode='extended',count = 100)\n",
    "# print(type(tweetList))\n",
    "# print(tweetList)\n",
    "# for tweets in tweetList.items(50):\n",
    "#     jsonString = tweets._json\n",
    "#     print(jsonString['id'], jsonString['created_at'],jsonString['full_text'].replace('\\n', ' '))\n",
    "#     print(tweets.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will generate a file containng the tweets of the data \n",
    "# This uses the tweepy API to fetch the data\n",
    "# TODO This method generate the maxind tweets twice. Will have to check on it.\n",
    "def searchTweetsByHashtag(searchlist):\n",
    "    # use this filter to filter the tweets based on the key words -filter:retweets AND -filter:replies\n",
    "    searchFilter = ' AND -filter:links and -filter:videos and -filter:retweets'\n",
    "    fileName = 'tweetDataset.csv'\n",
    "    with open (fileName,'a', newline='',encoding='utf-8') as sampleFile:\n",
    "        writer = csv.writer(sampleFile,quoting = csv.QUOTE_NONNUMERIC)\n",
    "        try:\n",
    "            for searchString in searchlist: \n",
    "                search_result = api.search(q=searchString + searchFilter,count=1,lang=\"en\",tweet_mode='extended'\n",
    "                                           , result_type  = 'recent')\n",
    "                if(len(search_result) == 0):\n",
    "                    print(\"*************No data on \"+ searchString +\" hashtag.***************\")\n",
    "                else : \n",
    "                    max_id = search_result[0].id\n",
    "                    #print(\"max_id\",max_id)\n",
    "                    old_id = -1\n",
    "                    i = 1\n",
    "                    while(max_id != old_id):\n",
    "                        old_id = max_id\n",
    "                        tweetDic = tweepy.Cursor(api.search,q = searchString + searchFilter  ,lang  = 'en'\n",
    "                                                 ,include_entities=False,tweet_mode='extended',count = 100\n",
    "                                                 ,max_id = max_id).items(300)\n",
    "                        print(\"loop count\",i)\n",
    "                        for tweets in tweetDic:\n",
    "                            jsonString = tweets._json\n",
    "                            #print(jsonString['id'],jsonString['full_text'].replace('\\n', ' '))\n",
    "                            csv_row = [jsonString['id'],jsonString['user']['screen_name'],jsonString['retweet_count']\n",
    "                                       ,jsonString['full_text'].replace('\\n', ' ')]  \n",
    "                            # we can also encode the text here to remove emojies from the text.\n",
    "                            max_id = jsonString['id'] + 1\n",
    "                            writer.writerow(csv_row)\n",
    "                        print(\"Going to sleep to keep limit to check\")    \n",
    "                        time.sleep(3)\n",
    "                        print(\"Waking Up\")\n",
    "                print(\"*************No more data to exact.*************\")\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Some error!!:\"+str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "*************No data on #Charlie'sAngels hashtag.***************\n",
      "*************No more data to exact.*************\n",
      "*************No data on #DoctorSleepReview hashtag.***************\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "loop count 1\n",
      "Going to sleep to keep limit to check\n",
      "Waking Up\n",
      "*************No more data to exact.*************\n",
      "*************No data on #JhalleReview hashtag.***************\n",
      "*************No more data to exact.*************\n"
     ]
    }
   ],
   "source": [
    "search_criteria = ['#MotichoorChaknachoorReview','#jhalkireview','#FordVsFerrari','#MotherlessBrooklyn'\n",
    "                   ,'#Charlie\\'sAngels','#DoctorSleepReview','#MidwayMovie','#Actionreview','#SangathamizhanReview'\n",
    "                  ,'#JhalleReview']\n",
    "searchTweetsByHashtag(search_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
